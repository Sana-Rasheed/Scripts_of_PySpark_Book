# -*- coding: utf-8 -*-
"""31-Read CSV file.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UEGijoQeLQ9lArUsMNUa_j6SbzAI3NmI
"""

import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[1]")\
          .appName("PySpark")\
          .getOrCreate()
df = spark.read.csv("/FileStore/tables/zipcodes-4.csv")
df.printSchema()

df = spark.read.format("csv")\
                  .load("/FileStore/tables/zipcodes-4.csv")
df.printSchema()

df2 = spark.read.option("header",True) \
     .csv("/FileStore/tables/zipcodes-4.csv")

df3 = spark.read.options(delimiter=',') \
  .csv("/FileStore/tables/zipcodes-4.csv")

df4 = spark.read.options(inferSchema='True',delimiter=',') \
  .csv("/FileStore/tables/zipcodes-4.csv")

df4 = spark.read.option("inferSchema",True) \
                .option("delimiter",",") \
  .csv("/FileStore/tables/zipcodes-4.csv")

df3 = spark.read.options(header='True', inferSchema='True', delimiter=',') \
  .csv("/FileStore/tables/zipcodes-4.csv")

from pyspark.sql.types import StructType,StructField, StringType, IntegerType 
from pyspark.sql.types import ArrayType, DoubleType, BooleanType
schema = StructType() \
      .add("RecordNumber",IntegerType(),True) \
      .add("Zipcode",IntegerType(),True) \
      .add("ZipCodeType",StringType(),True) \
      .add("City",StringType(),True) \
      .add("State",StringType(),True) \
      .add("LocationType",StringType(),True) \
      .add("Lat",DoubleType(),True) \
      .add("Long",DoubleType(),True) \
      .add("Xaxis",IntegerType(),True) \
      .add("Yaxis",DoubleType(),True) \
      .add("Zaxis",DoubleType(),True) \
      .add("WorldRegion",StringType(),True) \
      .add("Country",StringType(),True) \
      .add("LocationText",StringType(),True) \
      .add("Location",StringType(),True) \
      .add("Decommisioned",BooleanType(),True) \
      .add("TaxReturnsFiled",StringType(),True) \
      .add("EstimatedPopulation",IntegerType(),True) \
      .add("TotalWages",IntegerType(),True) \
      .add("Notes",StringType(),True)
      
df_with_schema = spark.read.format("csv") \
      .option("header", True) \
      .schema(schema) \
      .load("/FileStore/tables/zipcodes-4.csv")

df.write.option("header",True) \
 .csv("/tmp/spark_output/zipcode")

df2.write.options(header='True', delimiter=',') \
 .csv("/tmp/Spark_Output/zipcodes")

df2.write.mode('overwrite').csv("/tmp/spark_output/zipcode")
#you can also use this
df2.write.format("csv").mode('overwrite').save("/tmp/Spark_Output/zipcodes")

