{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import StringType, MapType\nmapCol = MapType(StringType(),StringType(),False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09bf935b-6b62-4d61-82dc-69c2105203cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructField, StructType, StringType, MapType\nschema = StructType([\n    StructField('name', StringType(), True),\n    StructField('properties', MapType(StringType(),StringType()),True)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53fb4d37-7e7c-426a-9e99-7b9e5f64d8f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('PySpark').getOrCreate()\ndataDictionary = [\n        ('James',{'hair':'black','eye':'brown'}),\n        ('Michael',{'hair':'brown','eye':None}),\n        ('Robert',{'hair':'red','eye':'black'}),\n        ('Washington',{'hair':'grey','eye':'grey'}),\n        ('Jefferson',{'hair':'brown','eye':''})\n        ]\ndf = spark.createDataFrame(data=dataDictionary, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"142cbba4-7b62-49f6-967a-a073c7e84fea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -&gt; brown, hair -&gt; black}|\n|Michael   |{eye -&gt; null, hair -&gt; brown} |\n|Robert    |{eye -&gt; black, hair -&gt; red}  |\n|Washington|{eye -&gt; grey, hair -&gt; grey}  |\n|Jefferson |{eye -&gt; , hair -&gt; brown}     |\n+----------+-----------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- name: string (nullable = true)\n-- properties: map (nullable = true)\n    |-- key: string\n    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\nname      |properties                   |\n+----------+-----------------------------+\nJames     |{eye -&gt; brown, hair -&gt; black}|\nMichael   |{eye -&gt; null, hair -&gt; brown} |\nRobert    |{eye -&gt; black, hair -&gt; red}  |\nWashington|{eye -&gt; grey, hair -&gt; grey}  |\nJefferson |{eye -&gt; , hair -&gt; brown}     |\n+----------+-----------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df3=df.rdd.map(lambda x: \\\n    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n    .toDF([\"name\",\"hair\",\"eye\"])\ndf3.printSchema()\ndf3.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b880797-8966-46d5-b75a-6e6b9b1222da"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- name: string (nullable = true)\n |-- hair: string (nullable = true)\n |-- eye: string (nullable = true)\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- name: string (nullable = true)\n-- hair: string (nullable = true)\n-- eye: string (nullable = true)\n\n+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n  .drop(\"properties\") \\\n  .show()\n#OR\ndf.withColumn(\"hair\",df.properties[\"hair\"]) \\\n  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n  .drop(\"properties\") \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29010493-363b-403f-bf59-e3cef43943a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import explode\ndf.select(df.name,explode(df.properties)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"003b79a7-54dd-47e7-b40c-b33d4b3c73ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----+-----+\n|      name| key|value|\n+----------+----+-----+\n|     James| eye|brown|\n|     James|hair|black|\n|   Michael| eye| null|\n|   Michael|hair|brown|\n|    Robert| eye|black|\n|    Robert|hair|  red|\n|Washington| eye| grey|\n|Washington|hair| grey|\n| Jefferson| eye|     |\n| Jefferson|hair|brown|\n+----------+----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----+-----+\n      name| key|value|\n+----------+----+-----+\n     James| eye|brown|\n     James|hair|black|\n   Michael| eye| null|\n   Michael|hair|brown|\n    Robert| eye|black|\n    Robert|hair|  red|\nWashington| eye| grey|\nWashington|hair| grey|\n Jefferson| eye|     |\n Jefferson|hair|brown|\n+----------+----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import map_keys\ndf.select(df.name,map_keys(df.properties)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3f08ebd-6f5d-494c-be30-15ec7d330a20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+--------------------+\n|      name|map_keys(properties)|\n+----------+--------------------+\n|     James|         [eye, hair]|\n|   Michael|         [eye, hair]|\n|    Robert|         [eye, hair]|\n|Washington|         [eye, hair]|\n| Jefferson|         [eye, hair]|\n+----------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------------------+\n      name|map_keys(properties)|\n+----------+--------------------+\n     James|         [eye, hair]|\n   Michael|         [eye, hair]|\n    Robert|         [eye, hair]|\nWashington|         [eye, hair]|\n Jefferson|         [eye, hair]|\n+----------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import explode,map_keys\nkeysDF = df.select(explode(map_keys(df.properties))).distinct()\nkeysList = keysDF.rdd.map(lambda x:x[0]).collect()\nprint(keysList)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f508305f-c5b8-468c-9452-3b744b92006d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;eye&#39;, &#39;hair&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;eye&#39;, &#39;hair&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import map_values\ndf.select(df.name,map_values(df.properties)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e455db1c-20d4-49d3-a653-1c4c3709e862"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----------------------+\n|      name|map_values(properties)|\n+----------+----------------------+\n|     James|        [brown, black]|\n|   Michael|        [ null, brown]|\n|    Robert|          [black, red]|\n|Washington|          [grey, grey]|\n| Jefferson|             [, brown]|\n+----------+----------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------------------+\n      name|map_values(properties)|\n+----------+----------------------+\n     James|        [brown, black]|\n   Michael|        [ null, brown]|\n    Robert|          [black, red]|\nWashington|          [grey, grey]|\n Jefferson|             [, brown]|\n+----------+----------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('PySpark').getOrCreate()\n\ndataDictionary = [\n        ('James',{'hair':'black','eye':'brown'}),\n        ('Michael',{'hair':'brown','eye':None}),\n        ('Robert',{'hair':'red','eye':'black'}),\n        ('Washington',{'hair':'grey','eye':'grey'}),\n        ('Jefferson',{'hair':'brown','eye':''})\n        ]\ndf = spark.createDataFrame(data=dataDictionary, schema = ['name','properties'])\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"403f7407-09a1-4ce4-a454-4ce96cab462d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -&gt; brown, hair -&gt; black}|\n|Michael   |{eye -&gt; null, hair -&gt; brown} |\n|Robert    |{eye -&gt; black, hair -&gt; red}  |\n|Washington|{eye -&gt; grey, hair -&gt; grey}  |\n|Jefferson |{eye -&gt; , hair -&gt; brown}     |\n+----------+-----------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- name: string (nullable = true)\n-- properties: map (nullable = true)\n    |-- key: string\n    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\nname      |properties                   |\n+----------+-----------------------------+\nJames     |{eye -&gt; brown, hair -&gt; black}|\nMichael   |{eye -&gt; null, hair -&gt; brown} |\nRobert    |{eye -&gt; black, hair -&gt; red}  |\nWashington|{eye -&gt; grey, hair -&gt; grey}  |\nJefferson |{eye -&gt; , hair -&gt; brown}     |\n+----------+-----------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df3=df.rdd.map(lambda x: \\\n    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n    .toDF([\"name\",\"hair\",\"eye\"])\ndf3.printSchema()\ndf3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1875097-9d74-4222-97a1-61818a8c22f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- name: string (nullable = true)\n |-- hair: string (nullable = true)\n |-- eye: string (nullable = true)\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- name: string (nullable = true)\n-- hair: string (nullable = true)\n-- eye: string (nullable = true)\n\n+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n  .drop(\"properties\") \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b97b6d4-5d8f-4289-9243-acf3463dcc06"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"hair\",df.properties[\"hair\"]) \\\n  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n  .drop(\"properties\") \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65dc09ed-fa10-4270-b6c8-ae340c8f4ce2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+-----+\n      name| hair|  eye|\n+----------+-----+-----+\n     James|black|brown|\n   Michael|brown| null|\n    Robert|  red|black|\nWashington| grey| grey|\n Jefferson|brown|     |\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import explode,map_keys,col\nkeysDF = df.select(explode(map_keys(df.properties))).distinct()\nkeysList = keysDF.rdd.map(lambda x:x[0]).collect()\nkeyCols = list(map(lambda x: col(\"properties\").getItem(x).alias(str(x)), keysList))\ndf.select(df.name, *keyCols).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db444977-0f78-4cb4-8451-537fe99784fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+-----+-----+\n|      name|  eye| hair|\n+----------+-----+-----+\n|     James|brown|black|\n|   Michael| null|brown|\n|    Robert|black|  red|\n|Washington| grey| grey|\n| Jefferson|     |brown|\n+----------+-----+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+-----+\n      name|  eye| hair|\n+----------+-----+-----+\n     James|brown|black|\n   Michael| null|brown|\n    Robert|black|  red|\nWashington| grey| grey|\n Jefferson|     |brown|\n+----------+-----+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\n\nspark = SparkSession.builder.appName('PySpark').getOrCreate()\ndata = [ (\"36636\",\"Finance\",3000,\"USA\"), \n    (\"40288\",\"Finance\",5000,\"Aus\"), \n    (\"42114\",\"Sales\",3900,\"USA\"), \n    (\"39192\",\"Marketing\",2500,\"CAN\"), \n    (\"34534\",\"Sales\",6500,\"USA\") ]\nschema = StructType([\n     StructField('id', StringType(), True),\n     StructField('dept', StringType(), True),\n     StructField('salary', IntegerType(), True),\n     StructField('location', StringType(), True)\n     ])\n\ndf = spark.createDataFrame(data=data,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2309cf9-ec3f-4cc9-b553-49fa1b5cd054"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- location: string (nullable = true)\n\n+-----+---------+------+--------+\n|id   |dept     |salary|location|\n+-----+---------+------+--------+\n|36636|Finance  |3000  |USA     |\n|40288|Finance  |5000  |Aus     |\n|42114|Sales    |3900  |USA     |\n|39192|Marketing|2500  |CAN     |\n|34534|Sales    |6500  |USA     |\n+-----+---------+------+--------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: string (nullable = true)\n-- dept: string (nullable = true)\n-- salary: integer (nullable = true)\n-- location: string (nullable = true)\n\n+-----+---------+------+--------+\nid   |dept     |salary|location|\n+-----+---------+------+--------+\n36636|Finance  |3000  |USA     |\n40288|Finance  |5000  |Aus     |\n42114|Sales    |3900  |USA     |\n39192|Marketing|2500  |CAN     |\n34534|Sales    |6500  |USA     |\n+-----+---------+------+--------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Convert columns to Map\nfrom pyspark.sql.functions import col,lit,create_map\ndf = df.withColumn(\"propertiesMap\",create_map(\n        lit(\"salary\"),col(\"salary\"),\n        lit(\"location\"),col(\"location\")\n        )).drop(\"salary\",\"location\")\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26d97ced-053e-4fc3-9bb8-ad6df1a35b03"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- propertiesMap: map (nullable = false)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\n|id   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n|36636|Finance  |{salary -&gt; 3000, location -&gt; USA}|\n|40288|Finance  |{salary -&gt; 5000, location -&gt; Aus}|\n|42114|Sales    |{salary -&gt; 3900, location -&gt; USA}|\n|39192|Marketing|{salary -&gt; 2500, location -&gt; CAN}|\n|34534|Sales    |{salary -&gt; 6500, location -&gt; USA}|\n+-----+---------+---------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: string (nullable = true)\n-- dept: string (nullable = true)\n-- propertiesMap: map (nullable = false)\n    |-- key: string\n    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\nid   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n36636|Finance  |{salary -&gt; 3000, location -&gt; USA}|\n40288|Finance  |{salary -&gt; 5000, location -&gt; Aus}|\n42114|Sales    |{salary -&gt; 3900, location -&gt; USA}|\n39192|Marketing|{salary -&gt; 2500, location -&gt; CAN}|\n34534|Sales    |{salary -&gt; 6500, location -&gt; USA}|\n+-----+---------+---------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\nspark = SparkSession.builder.appName('PySpark').getOrCreate()\ndata = [ (\"36636\",\"Finance\",(3000,\"USA\")), \n    (\"40288\",\"Finance\",(5000,\"Aus\")), \n    (\"42114\",\"Sales\",(3900,\"USA\")), \n    (\"39192\",\"Marketing\",(2500,\"CAN\")), \n    (\"34534\",\"Sales\",(6500,\"USA\")) ]\nschema = StructType([\n     StructField('id', StringType(), True),\n     StructField('dept', StringType(), True),\n     StructField('properties', StructType([\n         StructField('salary', IntegerType(), True),\n         StructField('location', StringType(), True)\n         ]))\n     ])\n\ndf = spark.createDataFrame(data=data,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"391f54ea-9cc6-4a1f-814d-bd70ad152eb4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- properties: struct (nullable = true)\n |    |-- salary: integer (nullable = true)\n |    |-- location: string (nullable = true)\n\n+-----+---------+-----------+\n|id   |dept     |properties |\n+-----+---------+-----------+\n|36636|Finance  |{3000, USA}|\n|40288|Finance  |{5000, Aus}|\n|42114|Sales    |{3900, USA}|\n|39192|Marketing|{2500, CAN}|\n|34534|Sales    |{6500, USA}|\n+-----+---------+-----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: string (nullable = true)\n-- dept: string (nullable = true)\n-- properties: struct (nullable = true)\n    |-- salary: integer (nullable = true)\n    |-- location: string (nullable = true)\n\n+-----+---------+-----------+\nid   |dept     |properties |\n+-----+---------+-----------+\n36636|Finance  |{3000, USA}|\n40288|Finance  |{5000, Aus}|\n42114|Sales    |{3900, USA}|\n39192|Marketing|{2500, CAN}|\n34534|Sales    |{6500, USA}|\n+-----+---------+-----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Convert struct type to Map\nfrom pyspark.sql.functions import col,lit,create_map\ndf = df.withColumn(\"propertiesMap\",create_map(\n        lit(\"salary\"),col(\"properties.salary\"),\n        lit(\"location\"),col(\"properties.location\")\n        )).drop(\"properties\")\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce86109a-eb4e-4586-9a7e-a74ddaed114c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- propertiesMap: map (nullable = false)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\n|id   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n|36636|Finance  |{salary -&gt; 3000, location -&gt; USA}|\n|40288|Finance  |{salary -&gt; 5000, location -&gt; Aus}|\n|42114|Sales    |{salary -&gt; 3900, location -&gt; USA}|\n|39192|Marketing|{salary -&gt; 2500, location -&gt; CAN}|\n|34534|Sales    |{salary -&gt; 6500, location -&gt; USA}|\n+-----+---------+---------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: string (nullable = true)\n-- dept: string (nullable = true)\n-- propertiesMap: map (nullable = false)\n    |-- key: string\n    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\nid   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n36636|Finance  |{salary -&gt; 3000, location -&gt; USA}|\n40288|Finance  |{salary -&gt; 5000, location -&gt; Aus}|\n42114|Sales    |{salary -&gt; 3900, location -&gt; USA}|\n39192|Marketing|{salary -&gt; 2500, location -&gt; CAN}|\n34534|Sales    |{salary -&gt; 6500, location -&gt; USA}|\n+-----+---------+---------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e6841c2-5755-4f9b-83d2-cbe5df73c479"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"map type","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2511968976882605}},"nbformat":4,"nbformat_minor":0}
