{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('PySpark').getOrCreate()\ndata = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n        (\"Jen\",\"\",None)]\n\ncolumns = [\"name\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c4f6e6b-b38f-4f24-8eeb-d5fdfa965420"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+------+\n|   name|gender|salary|\n+-------+------+------+\n|  James|     M| 60000|\n|Michael|     M| 70000|\n| Robert|  null|400000|\n|  Maria|     F|500000|\n|    Jen|      |  null|\n+-------+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+------+\n   name|gender|salary|\n+-------+------+------+\n  James|     M| 60000|\nMichael|     M| 70000|\n Robert|  null|400000|\n  Maria|     F|500000|\n    Jen|      |  null|\n+-------+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import when\ndf2 = df.withColumn(\"new_gender\", when(df.gender == \"M\",\"Male\")\n                                 .when(df.gender == \"F\",\"Female\")\n                                 .when(df.gender.isNull() ,\"\")\n                                 .otherwise(df.gender))\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be36c521-d1f2-463f-b218-b9c8432b60a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+------+----------+\n|   name|gender|salary|new_gender|\n+-------+------+------+----------+\n|  James|     M| 60000|      Male|\n|Michael|     M| 70000|      Male|\n| Robert|  null|400000|          |\n|  Maria|     F|500000|    Female|\n|    Jen|      |  null|          |\n+-------+------+------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+------+----------+\n   name|gender|salary|new_gender|\n+-------+------+------+----------+\n  James|     M| 60000|      Male|\nMichael|     M| 70000|      Male|\n Robert|  null|400000|          |\n  Maria|     F|500000|    Female|\n    Jen|      |  null|          |\n+-------+------+------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndf2=df.select(col(\"*\"),when(df.gender == \"M\",\"Male\")\n                  .when(df.gender == \"F\",\"Female\")\n                  .when(df.gender.isNull() ,\"\")\n                  .otherwise(df.gender).alias(\"new_gender\"))\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"924ff063-16c2-4b91-b613-c75d46e63f9d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+------+----------+\n|   name|gender|salary|new_gender|\n+-------+------+------+----------+\n|  James|     M| 60000|      Male|\n|Michael|     M| 70000|      Male|\n| Robert|  null|400000|          |\n|  Maria|     F|500000|    Female|\n|    Jen|      |  null|          |\n+-------+------+------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+------+----------+\n   name|gender|salary|new_gender|\n+-------+------+------+----------+\n  James|     M| 60000|      Male|\nMichael|     M| 70000|      Male|\n Robert|  null|400000|          |\n  Maria|     F|500000|    Female|\n    Jen|      |  null|          |\n+-------+------+------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import expr\n\n#Using Case When on withColumn()\ndf3 = df.withColumn(\"new_gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" + \n               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n               \"ELSE gender END\"))\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6edf3c55-665f-44ba-9159-02273bc22b38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+------+----------+\nname   |gender|salary|new_gender|\n+-------+------+------+----------+\nJames  |M     |60000 |Male      |\nMichael|M     |70000 |Male      |\nRobert |null  |400000|          |\nMaria  |F     |500000|Female    |\nJen    |      |null  |          |\n+-------+------+------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Using Case When on select()\ndf4 = df.select(col(\"*\"), expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n           \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n           \"ELSE gender END\").alias(\"new_gender\"))\ndf4.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70f03a04-347c-4f8c-aaef-233697a38f5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+------+----------+\nname   |gender|salary|new_gender|\n+-------+------+------+----------+\nJames  |M     |60000 |Male      |\nMichael|M     |70000 |Male      |\nRobert |null  |400000|          |\nMaria  |F     |500000|Female    |\nJen    |      |null  |          |\n+-------+------+------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.createOrReplaceTempView(\"EMP\")\nspark.sql(\"select name, CASE WHEN gender = 'M' THEN 'Male' \" + \n               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n              \"ELSE gender END as new_gender from EMP\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4c3538a-83d6-492c-bf65-769f9acb5177"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+----------+\n|   name|new_gender|\n+-------+----------+\n|  James|      Male|\n|Michael|      Male|\n| Robert|          |\n|  Maria|    Female|\n|    Jen|          |\n+-------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----------+\n   name|new_gender|\n+-------+----------+\n  James|      Male|\nMichael|      Male|\n Robert|          |\n  Maria|    Female|\n    Jen|          |\n+-------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Concatenate columns using || (sql like)\ndata=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")] \ndf=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \ndf.withColumn(\"Name\",expr(\" col1 ||','|| col2\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a65ba471-e891-4b63-97be-e259c068432c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+-----+-----------+\n| col1| col2|       Name|\n+-----+-----+-----------+\n|James| Bond| James,Bond|\n|Scott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+-----------+\n col1| col2|       Name|\n+-----+-----+-----------+\nJames| Bond| James,Bond|\nScott|Varsa|Scott,Varsa|\n+-----+-----+-----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import expr\ndata = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\ncolumns = [\"name\",\"gender\"]\ndf = spark.createDataFrame(data = data, schema = columns)\n\n#Using CASE WHEN similar to SQL.\nfrom pyspark.sql.functions import expr\ndf2=df.withColumn(\"gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9de51467-8db6-4a65-bc59-20d4539e103a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+-------+\n|   name| gender|\n+-------+-------+\n|  James|   Male|\n|Michael| Female|\n|    Jen|unknown|\n+-------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------+\n   name| gender|\n+-------+-------+\n  James|   Male|\nMichael| Female|\n    Jen|unknown|\n+-------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import expr\ndata=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)] \ndf=spark.createDataFrame(data).toDF(\"date\",\"increment\") \n\n#Add Month value from another column\ndf.select(df.date,df.increment,\n     expr(\"add_months(date,increment)\")\n  .alias(\"inc_date\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a697963-6322-4fee-89e7-161feb7d7a3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+---------+----------+\n      date|increment|  inc_date|\n+----------+---------+----------+\n2019-01-23|        1|2019-02-23|\n2019-06-24|        2|2019-08-24|\n2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Providing alias using 'as'\nfrom pyspark.sql.functions import expr\ndf.select(df.date,df.increment,\n     expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64c27cee-67a0-4d98-98b0-ecf22bea50d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+---------+----------+\n|      date|increment|  inc_date|\n+----------+---------+----------+\n|2019-01-23|        1|2019-02-23|\n|2019-06-24|        2|2019-08-24|\n|2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+---------+----------+\n      date|increment|  inc_date|\n+----------+---------+----------+\n2019-01-23|        1|2019-02-23|\n2019-06-24|        2|2019-08-24|\n2019-09-20|        3|2019-12-20|\n+----------+---------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Using Cast() Function\ndf.select(\"increment\",expr(\"cast(increment as string) as str_increment\")) \\\n  .printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea35e208-e887-4390-b502-07c193adc89f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- increment: long (nullable = true)\n |-- str_increment: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- increment: long (nullable = true)\n-- str_increment: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Arthemetic operations\ndf.select(df.date,df.increment,\n     expr(\"increment + 5 as new_increment\")\n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5be6cca-fa31-46e8-9b17-cb0b067b4d6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+---------+-------------+\n|      date|increment|new_increment|\n+----------+---------+-------------+\n|2019-01-23|        1|            6|\n|2019-06-24|        2|            7|\n|2019-09-20|        3|            8|\n+----------+---------+-------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+---------+-------------+\n      date|increment|new_increment|\n+----------+---------+-------------+\n2019-01-23|        1|            6|\n2019-06-24|        2|            7|\n2019-09-20|        3|            8|\n+----------+---------+-------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Use expr()  to filter the rows\nfrom pyspark.sql.functions import expr\ndata=[(100,2),(200,3000),(500,500)] \ndf=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \ndf.filter(expr(\"col1 == col2\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a638cc15-fcae-415f-b30a-00cc2e9f83c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----+----+\n|col1|col2|\n+----+----+\n| 500| 500|\n+----+----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\ncol1|col2|\n+----+----+\n 500| 500|\n+----+----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10f7de8d-d180-42d2-a4c6-49fc1e6fa28b"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"SQL Case When","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3540515798118453}},"nbformat":4,"nbformat_minor":0}
